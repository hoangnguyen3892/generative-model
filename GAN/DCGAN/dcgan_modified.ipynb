{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os\n",
    "import importlib\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.autograd as autograd\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "import torchvision.utils as vutils\n",
    "from torchnet.meter import AverageValueMeter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "parser = {\n",
    "    'dataset': 'cifar10',\n",
    "    'dataroot': './data',\n",
    "    'workers': 2,\n",
    "    'batchSize': 64,\n",
    "    'imageSize': 64,\n",
    "    'nz': 100,\n",
    "    'ngf': 64,\n",
    "    'ndf': 64,\n",
    "    'epochs': 25, \n",
    "    'lr': 1e-3,\n",
    "    'beta1': 0.5,\n",
    "    'netG': '',\n",
    "    'netD': '',\n",
    "    'outf': './output',\n",
    "    'ngpu': 0,\n",
    "    'manualSeed': 7,\n",
    "    'no_cuda': True,\n",
    "}\n",
    "args = argparse.Namespace(**parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batchSize=64, beta1=0.5, dataroot='./data', dataset='cifar10', epochs=25, imageSize=64, lr=0.001, manualSeed=7, ndf=64, netD='', netG='', ngf=64, ngpu=0, no_cuda=True, nz=100, outf='./output', workers=2)\n"
     ]
    }
   ],
   "source": [
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ngpu = int(args.ngpu)\n",
    "nz = int(args.nz)\n",
    "ngf = int(args.ngf)\n",
    "ndf = int(args.ndf)\n",
    "nc = 3  #rgb: image chanel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "dataset = dset.CIFAR10(root=args.dataroot, download=True, transform=transforms.Compose([\n",
    "                                                        transforms.Scale(args.imageSize),\n",
    "                                                        transforms.ToTensor(),\n",
    "                                                        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]))\n",
    "\n",
    "assert dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=args.batchSize, shuffle=True, num_workers=int(args.workers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Define class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# custom weights initialization called on netG and netD\n",
    "# m: layer of model\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__  #returns the name of class of m\n",
    "    if classname.find('Conv') != -1:  #name contains Conv\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1: #name contains BatchNorm, this can be seen like activation function after batchnorm\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "```class torch.nn.BatchNorm2d(num_features, eps=1e-05, momentum=0.1, affine=True)```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "```python\n",
    "def __init__(self):\n",
    "        self._backend = thnn_backend\n",
    "        self._parameters = OrderedDict()\n",
    "        self._buffers = OrderedDict()\n",
    "        self._backward_hooks = OrderedDict()\n",
    "        self._forward_hooks = OrderedDict()\n",
    "        self._modules = OrderedDict()\n",
    "        self.training = True\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "```class torch.nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Define class Discriminator:\n",
    "class _netG(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(_netG, self).__init__()  #no need to list __init__ of nn.Module\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*2) x 16 x 16\n",
    "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf) x 32 x 32\n",
    "            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. (nc) x 64 x 64 --> image size = 64\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        gpu_ids = None\n",
    "        #if isinstance(input.data, torch.cuda.FloatTensor) and self.ngpu > 1:\n",
    "            #gpu_ids = range(self.ngpu)\n",
    "        return nn.parallel.data_parallel(self.main, input, gpu_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_netG (\n",
      "  (main): Sequential (\n",
      "    (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (2): ReLU (inplace)\n",
      "    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (5): ReLU (inplace)\n",
      "    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (8): ReLU (inplace)\n",
      "    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (11): ReLU (inplace)\n",
      "    (12): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (13): Tanh ()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "netG = _netG(ngpu)\n",
    "netG.apply(weights_init)\n",
    "if args.netG != '':\n",
    "    netG.load_state_dict(torch.load(args.netG))\n",
    "print(netG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "```class torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class _netD(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(_netD, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # input is (nc) x 64 x 64\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf) x 32 x 32\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*2) x 16 x 16\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*4) x 8 x 8\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*8) x 4 x 4\n",
    "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        gpu_ids = None\n",
    "        if isinstance(input.data, torch.cuda.FloatTensor) and self.ngpu > 1:\n",
    "            gpu_ids = range(self.ngpu)\n",
    "        output = nn.parallel.data_parallel(self.main, input, gpu_ids)\n",
    "        return output.view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_netD (\n",
      "  (main): Sequential (\n",
      "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): LeakyReLU (0.2, inplace)\n",
      "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (4): LeakyReLU (0.2, inplace)\n",
      "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (7): LeakyReLU (0.2, inplace)\n",
      "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (10): LeakyReLU (0.2, inplace)\n",
      "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (12): Sigmoid ()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "netD = _netD(ngpu)\n",
    "netD.apply(weights_init)\n",
    "if args.netD != '':\n",
    "    netD.load_state_dict(torch.load(args.netD))\n",
    "print(netD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "```class torch.optim.Adam(params, lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "optimizerD = optim.Adam(netD.parameters(), lr=args.lr, betas=(args.beta1, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=args.lr, betas=(args.beta1, 0.999))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**NOTE**: \n",
    "if update Pytorch, the steps when training will be changed:\n",
    "\n",
    "buffer --> backward --> update _**CHANGED TO**_ backward --> buffer --> update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    for i, (X, _) in enumerate(dataloader):\n",
    "        \n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "        \n",
    "        \n",
    "        # Create ones_label and zeros_label\n",
    "        ones_label = Variable(torch.ones(X.size(0)))\n",
    "        zeros_label = Variable(torch.zeros(X.size(0)))\n",
    "        z = Variable(torch.randn(X.size(0), nz, 1,1))\n",
    "        \n",
    "        #train with real\n",
    "        X = Variable(X)\n",
    "        output = netD(X)\n",
    "        errD_real = criterion(output, ones_label)\n",
    "        \n",
    "        netD.zero_grad()\n",
    "        errD_real.backward()\n",
    "        \n",
    "        D_x = output.data.mean()\n",
    "        \n",
    "        #train with fake\n",
    "        fake = netG(z)\n",
    "        output = netD(fake.detach())   #Use detach so we just need to creat z once\n",
    "        errD_fake = criterion(output, zeros_label)\n",
    "        \n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.data.mean()\n",
    "        \n",
    "        \n",
    "        errD = errD_real + errD_fake\n",
    "        optimizerD.step()\n",
    "        \n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "        \n",
    "        output = netD(fake)\n",
    "        errG = criterion(output, ones_label)\n",
    "        \n",
    "        netG.zero_grad()\n",
    "        errG.backward()\n",
    "        \n",
    "        D_G_z2 = output.data.mean()\n",
    "        \n",
    "        optimizerG.step()\n",
    "        \n",
    "        print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f / %.4f'\n",
    "              % (epoch, args.epochs, i, len(dataloader),\n",
    "                 errD.data[0], errG.data[0], D_x, D_G_z1, D_G_z2))\n",
    "        if i % 100 == 0:\n",
    "            plot(X, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot(X, epoch):\n",
    "    z = Variable(torch.randn(X.size(0), nz, 1,1))\n",
    "    vutils.save_image(X.data, '%s/real_samples.png' % args.outf)\n",
    "    fake = netG(z)\n",
    "    vutils.save_image(fake.data,\n",
    "                    '%s/fake_samples_epoch_%03d.png' % (args.outf, epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/25][0/782] Loss_D: 27.6335 Loss_G: -0.0000 D(x): 0.9977 D(G(z)): 1.0000 / 1.0000\n",
      "[1/25][1/782] Loss_D: 27.6315 Loss_G: -0.0000 D(x): 0.9995 D(G(z)): 1.0000 / 1.0000\n",
      "[1/25][2/782] Loss_D: 27.6312 Loss_G: -0.0000 D(x): 0.9998 D(G(z)): 1.0000 / 1.0000\n",
      "[1/25][3/782] Loss_D: 27.6311 Loss_G: -0.0000 D(x): 0.9999 D(G(z)): 1.0000 / 1.0000\n",
      "[1/25][4/782] Loss_D: 27.6313 Loss_G: -0.0000 D(x): 0.9998 D(G(z)): 1.0000 / 1.0000\n",
      "[1/25][5/782] Loss_D: 27.6311 Loss_G: -0.0000 D(x): 0.9999 D(G(z)): 1.0000 / 1.0000\n",
      "[1/25][6/782] Loss_D: 27.6312 Loss_G: -0.0000 D(x): 0.9998 D(G(z)): 1.0000 / 1.0000\n",
      "[1/25][7/782] Loss_D: 27.6317 Loss_G: -0.0000 D(x): 0.9993 D(G(z)): 1.0000 / 1.0000\n",
      "[1/25][8/782] Loss_D: 27.6311 Loss_G: -0.0000 D(x): 0.9999 D(G(z)): 1.0000 / 1.0000\n",
      "[1/25][9/782] Loss_D: 27.6311 Loss_G: -0.0000 D(x): 0.9999 D(G(z)): 1.0000 / 1.0000\n",
      "[1/25][10/782] Loss_D: 27.6311 Loss_G: -0.0000 D(x): 0.9999 D(G(z)): 1.0000 / 1.0000\n",
      "[1/25][11/782] Loss_D: 27.6316 Loss_G: -0.0000 D(x): 0.9994 D(G(z)): 1.0000 / 1.0000\n",
      "[1/25][12/782] Loss_D: 27.6311 Loss_G: -0.0000 D(x): 0.9999 D(G(z)): 1.0000 / 1.0000\n",
      "[1/25][13/782] Loss_D: 27.6311 Loss_G: -0.0000 D(x): 0.9999 D(G(z)): 1.0000 / 1.0000\n",
      "[1/25][14/782] Loss_D: 27.6317 Loss_G: -0.0000 D(x): 0.9993 D(G(z)): 1.0000 / 1.0000\n",
      "[1/25][15/782] Loss_D: 27.6311 Loss_G: -0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
      "[1/25][16/782] Loss_D: 27.6311 Loss_G: -0.0000 D(x): 0.9999 D(G(z)): 1.0000 / 1.0000\n",
      "[1/25][17/782] Loss_D: 27.6416 Loss_G: -0.0000 D(x): 0.9922 D(G(z)): 1.0000 / 1.0000\n",
      "[1/25][18/782] Loss_D: 27.6311 Loss_G: -0.0000 D(x): 0.9999 D(G(z)): 1.0000 / 1.0000\n",
      "[1/25][19/782] Loss_D: 27.6312 Loss_G: -0.0000 D(x): 0.9998 D(G(z)): 1.0000 / 1.0000\n",
      "[1/25][20/782] Loss_D: 27.6310 Loss_G: -0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
      "[1/25][21/782] Loss_D: 27.6310 Loss_G: -0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
      "[1/25][22/782] Loss_D: 27.6310 Loss_G: -0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
      "[1/25][23/782] Loss_D: 27.6310 Loss_G: -0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
      "[1/25][24/782] Loss_D: 27.6310 Loss_G: -0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
      "[1/25][25/782] Loss_D: 27.6311 Loss_G: -0.0000 D(x): 0.9999 D(G(z)): 1.0000 / 1.0000\n",
      "[1/25][26/782] Loss_D: 27.6315 Loss_G: -0.0000 D(x): 0.9995 D(G(z)): 1.0000 / 1.0000\n",
      "[1/25][27/782] Loss_D: 27.6310 Loss_G: -0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
      "[1/25][28/782] Loss_D: 27.6311 Loss_G: -0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
      "[1/25][29/782] Loss_D: 27.6311 Loss_G: -0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
      "[1/25][30/782] Loss_D: 27.6310 Loss_G: -0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
      "[1/25][31/782] Loss_D: 27.6311 Loss_G: -0.0000 D(x): 0.9999 D(G(z)): 1.0000 / 1.0000\n",
      "[1/25][32/782] Loss_D: 27.6310 Loss_G: -0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
      "[1/25][33/782] Loss_D: 27.6310 Loss_G: -0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
      "[1/25][34/782] Loss_D: 27.6311 Loss_G: -0.0000 D(x): 0.9999 D(G(z)): 1.0000 / 1.0000\n",
      "[1/25][35/782] Loss_D: 27.6310 Loss_G: -0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
      "[1/25][36/782] Loss_D: 27.6311 Loss_G: -0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
      "[1/25][37/782] Loss_D: 27.6310 Loss_G: -0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
      "[1/25][38/782] Loss_D: 27.6310 Loss_G: -0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
      "[1/25][39/782] Loss_D: 27.6311 Loss_G: -0.0000 D(x): 0.9999 D(G(z)): 1.0000 / 1.0000\n",
      "[1/25][40/782] Loss_D: 27.6310 Loss_G: -0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
      "[1/25][41/782] Loss_D: 27.6311 Loss_G: -0.0000 D(x): 0.9999 D(G(z)): 1.0000 / 1.0000\n",
      "[1/25][42/782] Loss_D: 27.6311 Loss_G: -0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
      "[1/25][43/782] Loss_D: 27.6310 Loss_G: -0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
      "[1/25][44/782] Loss_D: 27.6310 Loss_G: -0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
      "[1/25][45/782] Loss_D: 27.6310 Loss_G: -0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
      "[1/25][46/782] Loss_D: 27.6310 Loss_G: -0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
      "[1/25][47/782] Loss_D: 27.6311 Loss_G: -0.0000 D(x): 0.9999 D(G(z)): 1.0000 / 1.0000\n",
      "[1/25][48/782] Loss_D: 27.6310 Loss_G: -0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
      "[1/25][49/782] Loss_D: 27.6310 Loss_G: -0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
      "[1/25][50/782] Loss_D: 27.6310 Loss_G: -0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
      "[1/25][51/782] Loss_D: 27.6311 Loss_G: -0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
      "[1/25][52/782] Loss_D: 27.6310 Loss_G: -0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
      "[1/25][53/782] Loss_D: 27.6311 Loss_G: -0.0000 D(x): 0.9999 D(G(z)): 1.0000 / 1.0000\n",
      "[1/25][54/782] Loss_D: 27.6310 Loss_G: -0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
      "[1/25][55/782] Loss_D: 27.6311 Loss_G: -0.0000 D(x): 0.9999 D(G(z)): 1.0000 / 1.0000\n",
      "[1/25][56/782] Loss_D: 27.6310 Loss_G: -0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
      "[1/25][57/782] Loss_D: 27.6311 Loss_G: -0.0000 D(x): 0.9999 D(G(z)): 1.0000 / 1.0000\n",
      "[1/25][58/782] Loss_D: 27.6310 Loss_G: -0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
      "[1/25][59/782] Loss_D: 27.6310 Loss_G: -0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
      "[1/25][60/782] Loss_D: 27.6311 Loss_G: -0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
      "[1/25][61/782] Loss_D: 27.6310 Loss_G: -0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
      "[1/25][62/782] Loss_D: 27.6310 Loss_G: -0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
      "[1/25][63/782] Loss_D: 27.6310 Loss_G: -0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
      "[1/25][64/782] Loss_D: 27.6310 Loss_G: -0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
      "[1/25][65/782] Loss_D: 27.6310 Loss_G: -0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
      "[1/25][66/782] Loss_D: 27.6310 Loss_G: -0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
      "[1/25][67/782] Loss_D: 27.6310 Loss_G: -0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
      "[1/25][68/782] Loss_D: 27.6311 Loss_G: -0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
      "[1/25][69/782] Loss_D: 27.6311 Loss_G: -0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
      "[1/25][70/782] Loss_D: 27.6310 Loss_G: -0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
      "[1/25][71/782] Loss_D: 27.6310 Loss_G: -0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
      "[1/25][72/782] Loss_D: 27.6311 Loss_G: -0.0000 D(x): 0.9999 D(G(z)): 1.0000 / 1.0000\n",
      "[1/25][73/782] Loss_D: 27.6310 Loss_G: -0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
      "[1/25][74/782] Loss_D: 27.6311 Loss_G: -0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-8:\n",
      "Process Process-7:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/hoangnguyen/miniconda3/envs/pydata/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/hoangnguyen/miniconda3/envs/pydata/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/hoangnguyen/miniconda3/envs/pydata/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/hoangnguyen/miniconda3/envs/pydata/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 26, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/Users/hoangnguyen/miniconda3/envs/pydata/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/hoangnguyen/miniconda3/envs/pydata/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/hoangnguyen/miniconda3/envs/pydata/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 26, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/Users/hoangnguyen/miniconda3/envs/pydata/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Users/hoangnguyen/miniconda3/envs/pydata/lib/python3.5/multiprocessing/queues.py\", line 343, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/hoangnguyen/miniconda3/envs/pydata/lib/python3.5/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/Users/hoangnguyen/miniconda3/envs/pydata/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/Users/hoangnguyen/miniconda3/envs/pydata/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-91d89439e44a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-d585e307e400>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m#train with fake\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mfake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m#Use detach so we just need to creat z once\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0merrD_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzeros_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hoangnguyen/miniconda3/envs/pydata/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-37fd46d3d093>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m#if isinstance(input.data, torch.cuda.FloatTensor) and self.ngpu > 1:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;31m#gpu_ids = range(self.ngpu)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_parallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpu_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/hoangnguyen/miniconda3/envs/pydata/lib/python3.5/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mdata_parallel\u001b[0;34m(module, input, device_ids, output_device)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdevice_ids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moutput_device\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hoangnguyen/miniconda3/envs/pydata/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hoangnguyen/miniconda3/envs/pydata/lib/python3.5/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hoangnguyen/miniconda3/envs/pydata/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hoangnguyen/miniconda3/envs/pydata/lib/python3.5/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, output_size)\u001b[0m\n\u001b[1;32m    521\u001b[0m         return F.conv_transpose2d(\n\u001b[1;32m    522\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m             output_padding, self.groups)\n\u001b[0m\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hoangnguyen/miniconda3/envs/pydata/lib/python3.5/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mconv_transpose2d\u001b[0;34m(input, weight, bias, stride, padding, output_padding, groups)\u001b[0m\n\u001b[1;32m    116\u001b[0m     f = ConvNd(_pair(stride), _pair(padding), _pair(1), True,\n\u001b[1;32m    117\u001b[0m                _pair(output_padding), groups)\n\u001b[0;32m--> 118\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hoangnguyen/miniconda3/envs/pydata/lib/python3.5/site-packages/torch/nn/_functions/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_view4d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_view3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hoangnguyen/miniconda3/envs/pydata/lib/python3.5/site-packages/torch/nn/_functions/conv.py\u001b[0m in \u001b[0;36m_update_output\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bufs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'update_output'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_grad_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hoangnguyen/miniconda3/envs/pydata/lib/python3.5/site-packages/torch/nn/_functions/conv.py\u001b[0m in \u001b[0;36m_thnn\u001b[0;34m(self, fn_name, input, weight, *args)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0mimpl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_thnn_convs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthnn_class_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mimpl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bufs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hoangnguyen/miniconda3/envs/pydata/lib/python3.5/site-packages/torch/nn/_functions/conv.py\u001b[0m in \u001b[0;36mcall_update_output\u001b[0;34m(self, bufs, input, weight, bias)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbufs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         getattr(backend, fn.name)(backend.library_state, input, output, weight,\n\u001b[0;32m--> 234\u001b[0;31m                                   bias, *args)\n\u001b[0m\u001b[1;32m    235\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_update_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 6):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "138px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
