{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os\n",
    "import importlib\n",
    "import argparse\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.autograd as autograd\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "import torchvision.utils as vutils\n",
    "from torchnet.meter import AverageValueMeter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "parser = {\n",
    "    'dataset': 'cifar10',\n",
    "    'dataroot': './data',\n",
    "    'workers': 2,\n",
    "    'batch_size': 64,\n",
    "    'image_size': 64,\n",
    "    'image_channels': 3,\n",
    "    'z_dim': 100,\n",
    "    'n_G': 64,\n",
    "    'n_D': 64,\n",
    "    'epochs': 25, \n",
    "    'lr': 1e-3,\n",
    "    'beta1': 0.5,\n",
    "    'netG': '',\n",
    "    'netD': '',\n",
    "    'outf': './output',\n",
    "    'ngpu': 0,\n",
    "    'manualSeed': 7,\n",
    "    'no_cuda': True,\n",
    "}\n",
    "args = argparse.Namespace(**parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=64, beta1=0.5, dataroot='./data', dataset='cifar10', epochs=25, image_channels=3, image_size=64, lr=0.001, manualSeed=7, n_D=64, n_G=64, netD='', netG='', ngpu=0, no_cuda=True, outf='./output', workers=2, z_dim=100)\n"
     ]
    }
   ],
   "source": [
    "print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "dataset = dset.CIFAR10(root=args.dataroot, download=True, transform=transforms.Compose([\n",
    "                                                        transforms.Scale(args.image_size),\n",
    "                                                        transforms.ToTensor(),\n",
    "                                                        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]))\n",
    "\n",
    "assert dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=args.batch_size, shuffle=True, num_workers=int(args.workers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Define class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# custom weights initialization called on netG and netD\n",
    "# m: layer of model\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__  #returns the name of class of m\n",
    "    if classname.find('Conv') != -1:  #name contains Conv\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1: #name contains BatchNorm, this can be seen like activation function after batchnorm\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "```class torch.nn.BatchNorm2d(num_features, eps=1e-05, momentum=0.1, affine=True)```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "```python\n",
    "def __init__(self):\n",
    "        self._backend = thnn_backend\n",
    "        self._parameters = OrderedDict()\n",
    "        self._buffers = OrderedDict()\n",
    "        self._backward_hooks = OrderedDict()\n",
    "        self._forward_hooks = OrderedDict()\n",
    "        self._modules = OrderedDict()\n",
    "        self.training = True\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "```class torch.nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Define class Discriminator:\n",
    "class _netG(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(_netG, self).__init__()  #no need to list __init__ of nn.Module\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d(args.z_dim, args.n_G * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(args.n_G * 8),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(args.n_G * 8, args.n_G * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(args.n_G * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d(args.n_G * 4, args.n_G * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(args.n_G * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*2) x 16 x 16\n",
    "            nn.ConvTranspose2d(args.n_G * 2, args.n_G, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(args.n_G),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf) x 32 x 32\n",
    "            nn.ConvTranspose2d(args.n_G, args.image_channels, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. (nc) x 64 x 64 --> image size = 64\n",
    "        )\n",
    "\n",
    "    #def forward(self, input):\n",
    "    #    gpu_ids = None\n",
    "    #    if isinstance(input.data, torch.cuda.FloatTensor) and self.ngpu > 1:\n",
    "    #       gpu_ids = range(self.ngpu)\n",
    "    #    return nn.parallel.data_parallel(self.main, input, gpu_ids)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_netG (\n",
      "  (main): Sequential (\n",
      "    (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (2): ReLU (inplace)\n",
      "    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (5): ReLU (inplace)\n",
      "    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (8): ReLU (inplace)\n",
      "    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (11): ReLU (inplace)\n",
      "    (12): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (13): Tanh ()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "netG = _netG(args.ngpu)\n",
    "netG.apply(weights_init)\n",
    "if args.netG != '':\n",
    "    netG.load_state_dict(torch.load(args.netG))\n",
    "print(netG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "```class torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class _netD(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(_netD, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # input is (nc) x 64 x 64\n",
    "            nn.Conv2d(args.image_channels, args.n_D, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf) x 32 x 32\n",
    "            nn.Conv2d(args.n_D, args.n_D * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(args.n_D * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*2) x 16 x 16\n",
    "            nn.Conv2d(args.n_D * 2, args.n_D * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(args.n_D * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*4) x 8 x 8\n",
    "            nn.Conv2d(args.n_D * 4, args.n_D * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(args.n_D * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*8) x 4 x 4\n",
    "            nn.Conv2d(args.n_D * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    #def forward(self, input):\n",
    "    #    gpu_ids = None\n",
    "    #    if isinstance(input.data, torch.cuda.FloatTensor) and self.ngpu > 1:\n",
    "    #        gpu_ids = range(self.ngpu)\n",
    "    #    output = nn.parallel.data_parallel(self.main, input, gpu_ids)\n",
    "    #   return output.view(-1, 1)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        output = self.main(input)\n",
    "        return output.view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_netD (\n",
      "  (main): Sequential (\n",
      "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): LeakyReLU (0.2, inplace)\n",
      "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (4): LeakyReLU (0.2, inplace)\n",
      "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (7): LeakyReLU (0.2, inplace)\n",
      "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (10): LeakyReLU (0.2, inplace)\n",
      "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (12): Sigmoid ()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "netD = _netD(args.ngpu)\n",
    "netD.apply(weights_init)\n",
    "if args.netD != '':\n",
    "    netD.load_state_dict(torch.load(args.netD))\n",
    "print(netD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "```class torch.optim.Adam(params, lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "optimizerD = optim.Adam(netD.parameters(), lr=args.lr, betas=(args.beta1, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=args.lr, betas=(args.beta1, 0.999))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**NOTE**: \n",
    "if update Pytorch, the steps when training will be changed:\n",
    "\n",
    "buffer --> backward --> update _**CHANGED TO**_ backward --> buffer --> update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def train(args, data_loader, netG, netD, G_optimizer, D_optimizer, criterion, epoch):\n",
    "    \n",
    "    D_losses = AverageValueMeter()\n",
    "    G_losses = AverageValueMeter()\n",
    "    D_reals = AverageValueMeter()        \n",
    "    D_fakes = AverageValueMeter()\n",
    "    G_reals = AverageValueMeter()\n",
    "        \n",
    "    start = time.time()\n",
    "    \n",
    "    for i, (real, _) in enumerate(dataloader):\n",
    "        batch_size = real.size(0)\n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "       \n",
    "        # Create ones_label and zeros_label\n",
    "        real_label = Variable(torch.ones(batch_size))\n",
    "        fake_label = Variable(torch.zeros(batch_size))\n",
    "        z = Variable(torch.randn(batch_size, args.z_dim, 1,1))\n",
    "        \n",
    "        #train with real\n",
    "        real = Variable(real)\n",
    "        real_output = netD(real)\n",
    "        \n",
    "        D_real_loss = criterion(real_output, real_label)\n",
    "        D_real = real_output.data.mean()\n",
    "\n",
    "        \n",
    "        #train with fake\n",
    "        fake = netG(z)\n",
    "        fake_output = netD(fake.detach())   #Use detach so we just need to creat z once\n",
    "        \n",
    "        D_fake_loss = criterion(fake_output, fake_label)\n",
    "        D_fake = fake_output.data.mean()\n",
    "        \n",
    "        D_loss = D_real_loss + D_fake_loss\n",
    "        netD.zero_grad()\n",
    "        D_loss.backward()\n",
    "        D_optimizer.step()\n",
    "        \n",
    "        \n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "        output = netD(fake)\n",
    "        G_loss = criterion(output, real_label)\n",
    "        G_real = output.data.mean()\n",
    "        \n",
    "        netG.zero_grad()\n",
    "        G_loss.backward()\n",
    "        G_optimizer.step()\n",
    "        \n",
    "        D_losses.add(D_loss.data.cpu()[0] * batch_size, batch_size)\n",
    "        G_losses.add(G_loss.data.cpu()[0] * batch_size, batch_size)\n",
    "        D_reals.add(D_real * batch_size, batch_size)\n",
    "        D_fakes.add(D_fake * batch_size, batch_size)\n",
    "        G_reals.add(G_real * batch_size, batch_size)\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            plot(real, epoch)\n",
    "        \n",
    "    print(\"=> EPOCH {} | Time: {}s | D_loss: {:.4f} | G_loss: {:.4f}\"\n",
    "          \" | D_real: {:.4f} | D_fake: {:.4f} | G_real: {:.4f}\"\n",
    "          .format(epoch, round(time.time()-start), D_losses.value()[0],\n",
    "                  G_losses.value()[0], D_reals.value()[0],\n",
    "                  D_fakes.value()[0], G_reals.value()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def plot(X, epoch):\n",
    "    z = Variable(torch.randn(X.size(0), args.z_dim, 1,1))\n",
    "    vutils.save_image(X.data, '%s/real_samples.png' % args.outf)\n",
    "    fake = netG(z)\n",
    "    vutils.save_image(fake.data,\n",
    "                    '%s/fake_samples_epoch_%03d.png' % (args.outf, epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for epoch in range(1, args.epochs+1):\n",
    "    train(args, dataloader, netG, netD, optimizerG, optimizerD, criterion, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "138px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
