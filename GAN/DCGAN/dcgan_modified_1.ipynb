{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os\n",
    "import importlib\n",
    "import argparse\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.autograd as autograd\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "import torchvision.utils as vutils\n",
    "from torchnet.meter import AverageValueMeter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "parser = {\n",
    "    'dataset': 'cifar10',\n",
    "    'dataroot': './data',\n",
    "    'workers': 2,\n",
    "    'batchSize': 64,\n",
    "    'imageSize': 64,\n",
    "    'image_channels': 3,\n",
    "    'nz': 100, #dim of latent variables\n",
    "    'ngf': 64, #number of G features\n",
    "    'ndf': 64, #number of D features\n",
    "    'epochs': 25, \n",
    "    'lr': 1e-3,\n",
    "    'beta1': 0.5, #for adam opt\n",
    "    'netG': '',\n",
    "    'netD': '',\n",
    "    'outf': './output',\n",
    "#    'ngpu': 0,\n",
    "    'manualSeed': 7,\n",
    "    'no_cuda': True,\n",
    "}\n",
    "args = argparse.Namespace(**parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batchSize=64, beta1=0.5, dataroot='./data', dataset='cifar10', epochs=25, imageSize=64, image_channels=3, lr=0.001, manualSeed=7, ndf=64, netD='', netG='', ngf=64, no_cuda=True, nz=100, outf='./output', workers=2)\n"
     ]
    }
   ],
   "source": [
    "print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "dataset = dset.CIFAR10(root=args.dataroot, download=True, transform=transforms.Compose([\n",
    "                                                        transforms.Scale(args.imageSize),\n",
    "                                                        transforms.ToTensor(),\n",
    "                                                        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]))\n",
    "\n",
    "assert dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=args.batchSize, shuffle=True, num_workers=int(args.workers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Define class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# custom weights initialization called on netG and netD\n",
    "# m: layer of model\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__  #returns the name of class of m\n",
    "    if classname.find('Conv') != -1:  #name contains Conv\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1: #name contains BatchNorm, this can be seen like activation function after batchnorm\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "```class torch.nn.BatchNorm2d(num_features, eps=1e-05, momentum=0.1, affine=True)```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "```python\n",
    "def __init__(self):\n",
    "        self._backend = thnn_backend\n",
    "        self._parameters = OrderedDict()\n",
    "        self._buffers = OrderedDict()\n",
    "        self._backward_hooks = OrderedDict()\n",
    "        self._forward_hooks = OrderedDict()\n",
    "        self._modules = OrderedDict()\n",
    "        self.training = True\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "```class torch.nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Define class Generator:\n",
    "class _netG(nn.Module):\n",
    "    #def __init__(self, ngpu):\n",
    "    def __init__(self):\n",
    "        super(_netG, self).__init__()  #no need to list __init__ of nn.Module\n",
    "        #self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d(args.nz, args.ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(args.ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(args.ngf * 8, args.ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(args.ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d(args.ngf * 4, args.ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(args.ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*2) x 16 x 16\n",
    "            nn.ConvTranspose2d(args.ngf * 2, args.ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(args.ngf),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf) x 32 x 32\n",
    "            nn.ConvTranspose2d(args.ngf, args.image_channels, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. (nc) x 64 x 64 --> image size = 64\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        #gpu_ids = None\n",
    "        #if isinstance(input.data, torch.cuda.FloatTensor) and self.ngpu > 1:\n",
    "            #gpu_ids = range(self.ngpu)\n",
    "        #return nn.parallel.data_parallel(self.main, input, gpu_ids)\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_netG (\n",
      "  (main): Sequential (\n",
      "    (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (2): ReLU (inplace)\n",
      "    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (5): ReLU (inplace)\n",
      "    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (8): ReLU (inplace)\n",
      "    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (11): ReLU (inplace)\n",
      "    (12): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (13): Tanh ()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "netG = _netG()\n",
    "netG.apply(weights_init)\n",
    "print(netG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "```class torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class _netD(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(_netD, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # input is (nc) x 64 x 64\n",
    "            nn.Conv2d(args.image_channels, args.ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf) x 32 x 32\n",
    "            nn.Conv2d(args.ndf, args.ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(args.ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*2) x 16 x 16\n",
    "            nn.Conv2d(args.ndf * 2, args.ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(args.ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*4) x 8 x 8\n",
    "            nn.Conv2d(args.ndf * 4, args.ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(args.ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*8) x 4 x 4\n",
    "            nn.Conv2d(args.ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        #output = nn.parallel.data_parallel(self.main, input, gpu_ids)\n",
    "        output = self.main(input)\n",
    "        return output.view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_netD (\n",
      "  (main): Sequential (\n",
      "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): LeakyReLU (0.2, inplace)\n",
      "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (4): LeakyReLU (0.2, inplace)\n",
      "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (7): LeakyReLU (0.2, inplace)\n",
      "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (10): LeakyReLU (0.2, inplace)\n",
      "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (12): Sigmoid ()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "netD = _netD()\n",
    "netD.apply(weights_init)\n",
    "print(netD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "```class torch.optim.Adam(params, lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "optimizerD = optim.Adam(netD.parameters(), lr=args.lr, betas=(args.beta1, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=args.lr, betas=(args.beta1, 0.999))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**NOTE**: \n",
    "if update Pytorch, the steps when training will be changed:\n",
    "\n",
    "buffer --> backward --> update _**CHANGED TO**_ backward --> buffer --> update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    D_losses = AverageValueMeter()\n",
    "    G_losses = AverageValueMeter()\n",
    "    D_real_accuracies = AverageValueMeter()\n",
    "    D_fake_accuracies = AverageValueMeter()\n",
    "    G_real_accuracies = AverageValueMeter()\n",
    "   \n",
    "    start = time.time()\n",
    "    for i, (real, _) in enumerate(dataloader):\n",
    "        \n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "        batch_size = real.size(0)\n",
    "        \n",
    "        # Create ones_label and zeros_label\n",
    "        real_label = Variable(torch.ones(batch_size))\n",
    "        fake_label = Variable(torch.zeros(batch_size))\n",
    "        z = Variable(torch.randn(batch_size, args.nz, 1,1))\n",
    "        \n",
    "        #train with real\n",
    "        real = Variable(real)\n",
    "        real_output = netD(real)\n",
    "        D_real_loss = criterion(real_output, real_label)\n",
    "        \n",
    "        netD.zero_grad()\n",
    "        D_real_loss.backward()\n",
    "        \n",
    "        \n",
    "        D_real_accuracy = real_output.data.mean()\n",
    "        \n",
    "        #train with fake\n",
    "        fake = netG(z)\n",
    "        fake_output = netD(fake.detach())   #Use detach so we just need to creat z once\n",
    "        D_fake_loss = criterion(fake_output, fake_label)\n",
    "        \n",
    "        D_fake_loss.backward()\n",
    "        D_fake_accuracy = fake_output.data.mean()\n",
    "        \n",
    "        \n",
    "        D_loss = D_real_loss + D_fake_loss\n",
    "        optimizerD.step()\n",
    "        \n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "        \n",
    "        output = netD(fake)\n",
    "        G_loss = criterion(output, real_label)\n",
    "        \n",
    "        netG.zero_grad()\n",
    "        G_loss.backward()\n",
    "        \n",
    "        G_real_accuracy = output.data.mean()\n",
    "        \n",
    "        optimizerG.step()\n",
    "        \n",
    "        D_losses.add(D_loss.data[0] * batch_size, batch_size)\n",
    "        G_losses.add(G_loss.data[0] * batch_size, batch_size)\n",
    "        D_real_accuracies.add(D_real_accuracy * batch_size, batch_size)\n",
    "        D_fake_accuracies.add(D_fake_accuracy * batch_size, batch_size)\n",
    "        G_real_accuracies.add(G_real_accuracy * batch_size, batch_size)\n",
    "        \n",
    "        print(\"=> EPOCH {:2d} | Time: {}s | D_loss: {:.3f} | G_loss: {:.3f} \"\n",
    "          \"| D_real_acc: {:.3f} | D_fake_acc: {:.3f} | G_real_acc: {:.3f}\"\n",
    "          .format(epoch, int(time.time()-start), D_losses.value()[0],\n",
    "                  G_losses.value()[0], D_real_accuracies.value()[0],\n",
    "                  D_fake_accuracies.value()[0], G_real_accuracies.value()[0]))\n",
    "    \n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            plot(real, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def plot(X, epoch):\n",
    "    z = Variable(torch.randn(X.size(0), args.nz, 1,1))\n",
    "    vutils.save_image(X.data, '%s/real_samples.png' % args.outf)\n",
    "    fake = netG(z)\n",
    "    vutils.save_image(fake.data,\n",
    "                    '%s/fake_samples_epoch_%03d.png' % (args.outf, epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> EPOCH  1 | Time: 4s | D_loss: 2.643 | G_loss: 27.404 | D_real_acc: 0.515 | D_fake_acc: 0.564 | G_real_acc: 0.000\n",
      "=> EPOCH  1 | Time: 12s | D_loss: 2.600 | G_loss: 25.877 | D_real_acc: 0.454 | D_fake_acc: 0.282 | G_real_acc: 0.000\n",
      "=> EPOCH  1 | Time: 17s | D_loss: 8.692 | G_loss: 24.875 | D_real_acc: 0.615 | D_fake_acc: 0.521 | G_real_acc: 0.000\n",
      "=> EPOCH  1 | Time: 22s | D_loss: 7.191 | G_loss: 25.449 | D_real_acc: 0.660 | D_fake_acc: 0.554 | G_real_acc: 0.000\n",
      "=> EPOCH  1 | Time: 26s | D_loss: 6.110 | G_loss: 25.781 | D_real_acc: 0.644 | D_fake_acc: 0.444 | G_real_acc: 0.000\n",
      "=> EPOCH  1 | Time: 31s | D_loss: 5.167 | G_loss: 25.208 | D_real_acc: 0.665 | D_fake_acc: 0.370 | G_real_acc: 0.000\n",
      "=> EPOCH  1 | Time: 35s | D_loss: 7.700 | G_loss: 22.776 | D_real_acc: 0.706 | D_fake_acc: 0.460 | G_real_acc: 0.017\n",
      "=> EPOCH  1 | Time: 40s | D_loss: 8.291 | G_loss: 21.899 | D_real_acc: 0.726 | D_fake_acc: 0.520 | G_real_acc: 0.017\n",
      "=> EPOCH  1 | Time: 45s | D_loss: 7.695 | G_loss: 20.743 | D_real_acc: 0.695 | D_fake_acc: 0.487 | G_real_acc: 0.016\n",
      "=> EPOCH  1 | Time: 49s | D_loss: 7.176 | G_loss: 19.463 | D_real_acc: 0.672 | D_fake_acc: 0.471 | G_real_acc: 0.014\n",
      "=> EPOCH  1 | Time: 54s | D_loss: 6.789 | G_loss: 18.621 | D_real_acc: 0.670 | D_fake_acc: 0.492 | G_real_acc: 0.013\n",
      "=> EPOCH  1 | Time: 58s | D_loss: 6.316 | G_loss: 17.716 | D_real_acc: 0.661 | D_fake_acc: 0.457 | G_real_acc: 0.012\n",
      "=> EPOCH  1 | Time: 62s | D_loss: 5.965 | G_loss: 17.158 | D_real_acc: 0.664 | D_fake_acc: 0.457 | G_real_acc: 0.012\n",
      "=> EPOCH  1 | Time: 67s | D_loss: 5.642 | G_loss: 16.406 | D_real_acc: 0.661 | D_fake_acc: 0.443 | G_real_acc: 0.014\n",
      "=> EPOCH  1 | Time: 72s | D_loss: 5.471 | G_loss: 15.682 | D_real_acc: 0.663 | D_fake_acc: 0.464 | G_real_acc: 0.015\n",
      "=> EPOCH  1 | Time: 78s | D_loss: 5.241 | G_loss: 14.990 | D_real_acc: 0.654 | D_fake_acc: 0.456 | G_real_acc: 0.018\n",
      "=> EPOCH  1 | Time: 83s | D_loss: 5.016 | G_loss: 14.354 | D_real_acc: 0.653 | D_fake_acc: 0.451 | G_real_acc: 0.020\n",
      "=> EPOCH  1 | Time: 88s | D_loss: 4.794 | G_loss: 13.828 | D_real_acc: 0.657 | D_fake_acc: 0.446 | G_real_acc: 0.020\n",
      "=> EPOCH  1 | Time: 94s | D_loss: 4.599 | G_loss: 13.275 | D_real_acc: 0.652 | D_fake_acc: 0.430 | G_real_acc: 0.023\n",
      "=> EPOCH  1 | Time: 100s | D_loss: 4.427 | G_loss: 12.849 | D_real_acc: 0.662 | D_fake_acc: 0.435 | G_real_acc: 0.025\n",
      "=> EPOCH  1 | Time: 105s | D_loss: 4.281 | G_loss: 12.405 | D_real_acc: 0.658 | D_fake_acc: 0.427 | G_real_acc: 0.027\n",
      "=> EPOCH  1 | Time: 112s | D_loss: 4.137 | G_loss: 12.011 | D_real_acc: 0.659 | D_fake_acc: 0.421 | G_real_acc: 0.029\n",
      "=> EPOCH  1 | Time: 118s | D_loss: 3.993 | G_loss: 11.608 | D_real_acc: 0.663 | D_fake_acc: 0.416 | G_real_acc: 0.032\n",
      "=> EPOCH  1 | Time: 124s | D_loss: 3.873 | G_loss: 11.280 | D_real_acc: 0.664 | D_fake_acc: 0.414 | G_real_acc: 0.033\n",
      "=> EPOCH  1 | Time: 129s | D_loss: 3.758 | G_loss: 10.971 | D_real_acc: 0.665 | D_fake_acc: 0.411 | G_real_acc: 0.035\n",
      "=> EPOCH  1 | Time: 134s | D_loss: 3.655 | G_loss: 10.726 | D_real_acc: 0.666 | D_fake_acc: 0.409 | G_real_acc: 0.035\n",
      "=> EPOCH  1 | Time: 139s | D_loss: 3.560 | G_loss: 10.458 | D_real_acc: 0.665 | D_fake_acc: 0.404 | G_real_acc: 0.038\n",
      "=> EPOCH  1 | Time: 143s | D_loss: 3.483 | G_loss: 10.234 | D_real_acc: 0.667 | D_fake_acc: 0.408 | G_real_acc: 0.038\n",
      "=> EPOCH  1 | Time: 148s | D_loss: 3.398 | G_loss: 9.990 | D_real_acc: 0.666 | D_fake_acc: 0.403 | G_real_acc: 0.039\n",
      "=> EPOCH  1 | Time: 155s | D_loss: 3.323 | G_loss: 9.780 | D_real_acc: 0.665 | D_fake_acc: 0.403 | G_real_acc: 0.039\n",
      "=> EPOCH  1 | Time: 160s | D_loss: 3.261 | G_loss: 9.526 | D_real_acc: 0.661 | D_fake_acc: 0.403 | G_real_acc: 0.045\n",
      "=> EPOCH  1 | Time: 165s | D_loss: 3.212 | G_loss: 9.437 | D_real_acc: 0.664 | D_fake_acc: 0.408 | G_real_acc: 0.044\n",
      "=> EPOCH  1 | Time: 170s | D_loss: 3.199 | G_loss: 9.216 | D_real_acc: 0.651 | D_fake_acc: 0.399 | G_real_acc: 0.052\n",
      "=> EPOCH  1 | Time: 176s | D_loss: 3.150 | G_loss: 9.033 | D_real_acc: 0.657 | D_fake_acc: 0.404 | G_real_acc: 0.054\n",
      "=> EPOCH  1 | Time: 183s | D_loss: 3.114 | G_loss: 8.892 | D_real_acc: 0.655 | D_fake_acc: 0.407 | G_real_acc: 0.055\n",
      "=> EPOCH  1 | Time: 187s | D_loss: 3.079 | G_loss: 8.691 | D_real_acc: 0.648 | D_fake_acc: 0.404 | G_real_acc: 0.061\n",
      "=> EPOCH  1 | Time: 191s | D_loss: 3.039 | G_loss: 8.558 | D_real_acc: 0.648 | D_fake_acc: 0.409 | G_real_acc: 0.061\n",
      "=> EPOCH  1 | Time: 196s | D_loss: 2.993 | G_loss: 8.374 | D_real_acc: 0.644 | D_fake_acc: 0.402 | G_real_acc: 0.066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-14:\n",
      "Process Process-13:\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/hoangnguyen/miniconda3/envs/pydata/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/hoangnguyen/miniconda3/envs/pydata/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/hoangnguyen/miniconda3/envs/pydata/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/hoangnguyen/miniconda3/envs/pydata/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/hoangnguyen/miniconda3/envs/pydata/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 26, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/Users/hoangnguyen/miniconda3/envs/pydata/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 26, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/Users/hoangnguyen/miniconda3/envs/pydata/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/hoangnguyen/miniconda3/envs/pydata/lib/python3.5/multiprocessing/queues.py\", line 343, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/Users/hoangnguyen/miniconda3/envs/pydata/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Users/hoangnguyen/miniconda3/envs/pydata/lib/python3.5/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/hoangnguyen/miniconda3/envs/pydata/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/Users/hoangnguyen/miniconda3/envs/pydata/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-91d89439e44a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-41-0149e4086d9c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mnetG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mG_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mG_real_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hoangnguyen/miniconda3/envs/pydata/lib/python3.5/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_variables)\u001b[0m\n\u001b[1;32m    143\u001b[0m                     'or with gradient w.r.t. the variable')\n\u001b[1;32m    144\u001b[0m             \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_as_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execution_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hoangnguyen/miniconda3/envs/pydata/lib/python3.5/site-packages/torch/nn/_functions/batchnorm.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad_output)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mgrad_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_bias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 6):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "138px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
